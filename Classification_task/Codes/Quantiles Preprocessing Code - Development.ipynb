{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be2f7c5",
   "metadata": {},
   "source": [
    "# Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b24b83",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/curve-fitting-with-python/\n",
    "\n",
    "https://study.com/academy/lesson/interpolation-in-statistics-definition-formula-example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdee0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numpy import corrcoef as pcor\n",
    "\n",
    "from numpy import exp as exp\n",
    "from scipy import spatial\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import glob\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def return_best_shapelet_pearson(vector):\n",
    "    correlation_lst = []\n",
    "    corrs = []\n",
    "    for i in range(len(shapelet_standard_array)):\n",
    "        score = similarity_metrix(shapelet_standard_array[i],vector)\n",
    "        correlation_lst.append(shapelet_standard_names[i])\n",
    "        corrs.append(score)\n",
    "    scenario = corrs.index(max(corrs))\n",
    "    return correlation_lst[scenario]\n",
    "\n",
    "    \n",
    "def return_all_shapelet_pearson(vector):\n",
    "#     correlation_lst = []\n",
    "    corrs = []\n",
    "    for i in range(len(shapelet_standard_array)):\n",
    "        score = similarity_metrix(shapelet_standard_array[i],vector)\n",
    "#         correlation_lst.append(shapelet_standard_names[i])\n",
    "        corrs.append(score)\n",
    "    return corrs\n",
    "\n",
    "\n",
    "\n",
    "def similarity_metrix(vector1,vector2):\n",
    "    '''\n",
    "    Here we have given user the flexibility to change the similarity function. Currently we have made it pearson correlation but it can be cosine\n",
    "    \n",
    "    1 - spatial.distance.cosine(vector1, vector2)\n",
    "    '''\n",
    "    similarity_value = round(pcor(vector1,vector2)[0][1],3)\n",
    "    return similarity_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0369a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_visualizations = False ### when this is set to True, visualizations will be expored. If False, visualizations will only be displayed not exported\n",
    "Data_refresh = 0 \n",
    "\n",
    "# Smoothening_param= 3 ### make it dynamic in code below \n",
    "\n",
    "\n",
    "### if it is set to 1, data processing of all models needs to be done. As is this needs to be set1 when we feel model data need to be updated else 0\n",
    "\n",
    "\n",
    "#### Ignore model List \n",
    "Ignore_model_list  = []\n",
    "\n",
    "Ignore_State_list = ['Illinois', 'Arizona', 'Massachusetts',\n",
    "       'Wisconsin', 'Texas', 'Nebraska', 'Utah', 'Oregon','United States','Washington',\n",
    "       'New York', 'Rhode Island', 'Georgia', 'New Hampshire',\n",
    "       'North Carolina', 'New Jersey', 'Colorado', 'Maryland', 'Nevada',\n",
    "       'Tennessee', 'Hawaii', 'Indiana', 'Kentucky', 'Minnesota',\n",
    "       'Oklahoma', 'Pennsylvania', 'South Carolina',\n",
    "       'District of Columbia', 'Kansas', 'Missouri', 'Vermont',\n",
    "       'Virginia', 'Connecticut', 'Iowa', 'Louisiana', 'Ohio', 'Michigan',\n",
    "       'South Dakota', 'Arkansas', 'Delaware', 'Mississippi',\n",
    "       'New Mexico', 'North Dakota', 'Wyoming', 'Alaska', 'Maine',\n",
    "       'Alabama', 'Idaho', 'Montana', 'Puerto Rico', 'Virgin Islands',\n",
    "       'Guam', 'West Virginia', 'Northern Mariana Islands',\n",
    "       'American Samoa']\n",
    "\n",
    "# select_state_list = [\"Florida\"]\n",
    "\n",
    "# State_list = [\"Florida\"]\n",
    "\n",
    "\n",
    "vector_length = (0,4)   ### 1 means using N-1 week value for defining shapelet and 4 weeks 4 weeks from future. 4 can't be changed because models generate only 4 weeks ahead predictions.\n",
    "## (0,4) means look 4 weeks ahead in future while defining shapelet\n",
    "## (1,4) means look 4 weeks ahead in future, 1 week in past basically N-1 week from actual covid incidence list for defining shapelet\n",
    "\n",
    "history_weeks = vector_length[0]\n",
    "\n",
    "future_weeks = vector_length[1]\n",
    "\n",
    "assert future_weeks<=4,\"Looking 4 weeks in future is fixed because our modelsgenerate 4 weeks ahead predictions. \\n Please change vector_length[1]\"\n",
    "\n",
    "\n",
    "Number_of_shapelets = 6 ### 6 \n",
    "\n",
    "global Shapelet_length\n",
    "Shapelet_length = vector_length[0]+vector_length[1]\n",
    "\n",
    "shapelet_standard_array = [[0]*Shapelet_length for w in range(Number_of_shapelets)]\n",
    "## here we have initialized an zero valued array of array.\n",
    "\n",
    "\n",
    "# Hyper Params \n",
    "\n",
    "shapelet_standard_names = [\"Flat\",\"Inc\",'Dec',\"Surge\",'Peaking',\"Near Peak\"]\n",
    "\n",
    "assert len(shapelet_standard_names)==Number_of_shapelets, 'Size of array mismatch for shapelet_standard_names and value of  Number_of_shapelets'\n",
    "# print('Size Mismacth')\n",
    "\n",
    "### for this experiment, we have defined following shapelets \n",
    "# flat = [1.0, 1.00000001, 1.00000002, 1.00000003, 1.00000004]\n",
    "# stable_inc = [1 ,2, 3, 4, 5]#, i.e., linear\n",
    "# stable_dec = [5, 4, 3 ,2, 1]#, i.e., linear but decreasing\n",
    "# surge =[exp(-1/2), exp(0/2), exp(1/2), exp(2/2), exp(3/2)]#, i.e., like exp(x)\n",
    "# peaking = [-1*w for w in [exp(1/2) ,exp(0/2), exp(-1/2), exp(-2/2), exp(-3/2)]]#, i.e., like -exp(-x)\n",
    "# at_near_peak=  [-1*w for w in [exp(-1/2) ,exp(0/2) ,exp(1/2) ,exp(2/2), exp(3/2)]]#, i.e., like -exp(x)\n",
    "\n",
    "shapelet_standard_array[0] = [1.0, 0, 1.0, 0.0000]\n",
    "shapelet_standard_array[1] = [1 ,2, 3, 4]\n",
    "shapelet_standard_array[2] = [5, 4, 3 ,2]\n",
    "shapelet_standard_array[3] = [1,2,4,8]\n",
    "shapelet_standard_array[4] = [-1*w for w in [exp(1/2) ,exp(0/2), exp(-1/2), exp(-2/2)]]\n",
    "shapelet_standard_array[5] = [-1*w for w in [exp(-1/2) ,exp(0/2) ,exp(1/2) ,exp(2/2)]]\n",
    "\n",
    "assert len(shapelet_standard_array[0])==Shapelet_length, 'Size of defined shapelet array mismatch for shapelet_standard_names and value of  Shapelet_length.please check vector_length'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa9210c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def valid_week_nbr(a_string):\n",
    "\n",
    "    if [int(word) for word in a_string.split() if word.isdigit()][0]<5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def interpolate(test_array):\n",
    "    inter_list= []\n",
    "    array_x = [w[0] for w in test_array]\n",
    "    array_y = [w[1] for w in test_array]\n",
    "#     sum_iter = 0\n",
    "    for i in range(50):\n",
    "        value_x = np.random.uniform(low=0.0, high=1.0)\n",
    "        y_inter = np.interp(value_x,array_x,array_y)\n",
    "        inter_list.append(round(y_inter,2))\n",
    "    return inter_list\n",
    "def return_Similarity_score_all(x):\n",
    "    try:\n",
    "    #     print(x[0][0])\n",
    "    #     frst_week = []\n",
    "        for item in x:\n",
    "            if item[0].find(\"1\")>-1:\n",
    "                frst_week=item[1]\n",
    "                break\n",
    "        second_week = []\n",
    "        for item in x:\n",
    "            if item[0].find(\"2\")>-1:\n",
    "                second_week=item[1]\n",
    "                break\n",
    "        thrd_week =[]\n",
    "        for item in x:\n",
    "            if item[0].find(\"3\")>-1:\n",
    "                thrd_week=item[1]\n",
    "                break\n",
    "        frth_week=[]\n",
    "        for item in x:\n",
    "            if item[0].find(\"4\")>-1:\n",
    "                frth_week=item[1]\n",
    "                break\n",
    "        interpolated_array = []\n",
    "\n",
    "\n",
    "        for i in range(len(frst_week)):\n",
    "            vector = [frst_week[i],second_week[i],thrd_week[i],frth_week[i]]\n",
    "    #         print(vector)\n",
    "            interpolated_array.append(return_all_shapelet_pearson(vector))\n",
    "\n",
    "\n",
    "        return interpolated_array\n",
    "    except:\n",
    "        return \"NAN\"\n",
    "    \n",
    "def aggregated_similarity(data):\n",
    "    try:\n",
    "        a = np.array(data)\n",
    "\n",
    "        aggs = a.mean(axis=0)\n",
    "\n",
    "        xx = [round(w,4) for w in aggs]\n",
    "        return xx\n",
    "    except:\n",
    "        print(data)\n",
    "    \n",
    "from datetime import date\n",
    "\n",
    "\n",
    "d0 = date(2020, 1, 22)\n",
    "\n",
    "def format_dt_int(w):\n",
    "    wsplit = w.split(\"-\")\n",
    "    yr = int(wsplit[0])\n",
    "    mth=int(wsplit[1])\n",
    "    dt = int(wsplit[2])\n",
    "    d1 = date(yr, mth, dt)\n",
    "    delta = d1 - d0\n",
    "    return delta.days\n",
    "\n",
    "import math\n",
    "def is_valid(x):\n",
    "    for i in x:\n",
    "        if math.isnan(i):\n",
    "            return 0\n",
    "    return 1             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4748911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source_path = \"../Data_Sources/quantile_preprocessing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ed0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "locatoins = pd.read_csv(Source_path+\"locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b667e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_mapping = locatoins[['location','location_name']].set_index(\"location\").to_dict()['location_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33f8f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_mapping['US']='United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5561ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'CEID-Walk'\n",
    "\n",
    "runtype = \"case\"\n",
    "\n",
    "valid_vals = ['US',\t '01',\t '02',\t '04',\t '05',\t '06',\t '08',\t '09',\t '10',\t '11',\t '12',\t '13',\t '15',\t '16',\t '17',\t '18',\t '19',\t '20',\t '21',\t '22',\t '23',\t '24',\t '25',\t '26',\t '27',\t '28',\t '29',\t '30',\t '31',\t '32',\t '33',\t '34',\t '35',\t '36',\t '37',\t '38',\t '39',\t '40',\t '41',\t '42',\t '44',\t '45',\t '46',\t '47',\t '48',\t '49',\t '50',\t '51',\t '53',\t '54',\t '55',\t '56',\t '60',\t '66',\t '69',\t '72',\t '74',\t '78']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc6608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498c90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = Source_path+\"2020-08-09-CEID-Walk.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eedf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = pd.read_csv(Source_path+\"2020-08-09-CEID-Walk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f1e689dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/Users/satwant/Downloads/CEID-Walk/\"\n",
    "\n",
    "root = '/Users/satwant/Downloads/covid19-forecast-hub-master/data-processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae417497",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = glob.glob(root+\"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c1ff497",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_master_df = pd.DataFrame()\n",
    "for path in model_root:\n",
    "    filenames = glob.glob(path+\"2*.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2714fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "    master_data = pd.DataFrame()\n",
    "    for i in filenames:\n",
    "        tmp = pd.read_csv(i)\n",
    "        ## filter for runtype\n",
    "        cases_data_tmp = tmp[tmp['target'].str.contains(runtype)]\n",
    "\n",
    "        ## filter for quantiles only \n",
    "\n",
    "        cases_data_tmp1 = cases_data_tmp[cases_data_tmp['type']=='quantile']\n",
    "\n",
    "        cases_data = cases_data_tmp1[cases_data_tmp1['location'].isin(valid_vals)]\n",
    "\n",
    "        cases_data['location'] = cases_data['location'].apply(lambda x : location_mapping.get(x,x)) \n",
    "\n",
    "        cases_data = cases_data[~cases_data['location'].isin(Ignore_State_list)]\n",
    "\n",
    "        cases_data['valid_row'] = cases_data['target'].apply(valid_week_nbr)\n",
    "\n",
    "        cases_data = cases_data[cases_data['valid_row']==1]\n",
    "\n",
    "        master_data = pd.concat([master_data,cases_data],axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d9d1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_data = master_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d89f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_data['ordered_pair'] =cases_data[['quantile', 'value']].apply(tuple, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22fcb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_subset = cases_data[['forecast_date','location','target','ordered_pair','target_end_date']]\n",
    "\n",
    "\n",
    "cases_rolledup = cases_subset.groupby(['forecast_date','location','target','target_end_date'])['ordered_pair'].apply(list).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5cade32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup['IR_value_50sim'] = cases_rolledup['ordered_pair'].apply(interpolate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "509072b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup['week_interpolated_array'] =cases_rolledup[['target', 'IR_value_50sim']].apply(tuple, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0486e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1 = cases_rolledup.groupby(['forecast_date','location'])['week_interpolated_array'].apply(list).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03811664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cases_rolledup1['All_iterpol_similar'] = cases_rolledup1['week_interpolated_array'].apply(return_Similarity_score_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e47bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1 = cases_rolledup1[cases_rolledup1['All_iterpol_similar']!='NAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9fff684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cases_rolledup1['aggregated_similarity'] = cases_rolledup1['All_iterpol_similar'].apply(aggregated_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00f28d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1['forecast_date1'] = cases_rolledup1['forecast_date'].apply(format_dt_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55fa5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1['model_name'] = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d945ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1_subset = cases_rolledup1[['forecast_date','model_name','forecast_date1','location','aggregated_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7108d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1_subset['valid_row'] = cases_rolledup1_subset['aggregated_similarity'].apply(is_valid)\n",
    "\n",
    "cases_rolledup1_subset = cases_rolledup1_subset[cases_rolledup1_subset[\"valid_row\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3dfa3c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>model_name</th>\n",
       "      <th>forecast_date1</th>\n",
       "      <th>location</th>\n",
       "      <th>aggregated_similarity</th>\n",
       "      <th>valid_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-09</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>200</td>\n",
       "      <td>California</td>\n",
       "      <td>[0.1535, -0.1034, 0.1034, -0.1334, -0.0818, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-09</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>200</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[0.0295, -0.0264, 0.0264, -0.0574, -0.0026, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-16</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>207</td>\n",
       "      <td>California</td>\n",
       "      <td>[0.1997, -0.1374, 0.1374, -0.1902, -0.0985, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-16</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>207</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[-0.0302, -0.0335, 0.0335, -0.034, -0.0287, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>214</td>\n",
       "      <td>California</td>\n",
       "      <td>[-0.1841, 0.0682, -0.0682, 0.119, 0.0357, -0.1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>824</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[-0.0136, -0.0014, 0.0014, 0.0228, -0.0186, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>831</td>\n",
       "      <td>California</td>\n",
       "      <td>[0.061, 0.0158, -0.0158, 0.012, 0.0137, -0.0136]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>831</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[0.1524, 0.0962, -0.0962, 0.0511, 0.1132, -0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>838</td>\n",
       "      <td>California</td>\n",
       "      <td>[0.0942, 0.1059, -0.1059, 0.1154, 0.0843, -0.1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>838</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[0.0587, -0.0626, 0.0626, -0.0952, -0.0365, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    forecast_date model_name  forecast_date1    location  \\\n",
       "0      2020-08-09  CEID-Walk             200  California   \n",
       "1      2020-08-09  CEID-Walk             200     Florida   \n",
       "2      2020-08-16  CEID-Walk             207  California   \n",
       "3      2020-08-16  CEID-Walk             207     Florida   \n",
       "4      2020-08-23  CEID-Walk             214  California   \n",
       "..            ...        ...             ...         ...   \n",
       "127    2022-04-25  CEID-Walk             824     Florida   \n",
       "128    2022-05-02  CEID-Walk             831  California   \n",
       "129    2022-05-02  CEID-Walk             831     Florida   \n",
       "130    2022-05-09  CEID-Walk             838  California   \n",
       "131    2022-05-09  CEID-Walk             838     Florida   \n",
       "\n",
       "                                 aggregated_similarity  valid_row  \n",
       "0    [0.1535, -0.1034, 0.1034, -0.1334, -0.0818, 0....          1  \n",
       "1    [0.0295, -0.0264, 0.0264, -0.0574, -0.0026, 0....          1  \n",
       "2    [0.1997, -0.1374, 0.1374, -0.1902, -0.0985, 0....          1  \n",
       "3    [-0.0302, -0.0335, 0.0335, -0.034, -0.0287, 0....          1  \n",
       "4    [-0.1841, 0.0682, -0.0682, 0.119, 0.0357, -0.1...          1  \n",
       "..                                                 ...        ...  \n",
       "127  [-0.0136, -0.0014, 0.0014, 0.0228, -0.0186, -0...          1  \n",
       "128   [0.061, 0.0158, -0.0158, 0.012, 0.0137, -0.0136]          1  \n",
       "129  [0.1524, 0.0962, -0.0962, 0.0511, 0.1132, -0.0...          1  \n",
       "130  [0.0942, 0.1059, -0.1059, 0.1154, 0.0843, -0.1...          1  \n",
       "131  [0.0587, -0.0626, 0.0626, -0.0952, -0.0365, 0....          1  \n",
       "\n",
       "[127 rows x 6 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_rolledup1_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9996f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192d059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37231bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa1cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f8936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
