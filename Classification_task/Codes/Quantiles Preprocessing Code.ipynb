{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be2f7c5",
   "metadata": {},
   "source": [
    "# Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b24b83",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/curve-fitting-with-python/\n",
    "\n",
    "https://study.com/academy/lesson/interpolation-in-statistics-definition-formula-example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52041c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numpy import corrcoef as pcor\n",
    "\n",
    "from numpy import exp as exp\n",
    "from scipy import spatial\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def return_best_shapelet_pearson(vector):\n",
    "    correlation_lst = []\n",
    "    corrs = []\n",
    "    for i in range(len(shapelet_standard_array)):\n",
    "        score = similarity_metrix(shapelet_standard_array[i],vector)\n",
    "        correlation_lst.append(shapelet_standard_names[i])\n",
    "        corrs.append(score)\n",
    "    scenario = corrs.index(max(corrs))\n",
    "    return correlation_lst[scenario]\n",
    "\n",
    "    \n",
    "def return_all_shapelet_pearson(vector):\n",
    "#     correlation_lst = []\n",
    "    corrs = []\n",
    "    for i in range(len(shapelet_standard_array)):\n",
    "        score = similarity_metrix(shapelet_standard_array[i],vector)\n",
    "#         correlation_lst.append(shapelet_standard_names[i])\n",
    "        corrs.append(score)\n",
    "    return corrs\n",
    "\n",
    "\n",
    "\n",
    "def similarity_metrix(vector1,vector2):\n",
    "    '''\n",
    "    Here we have given user the flexibility to change the similarity function. Currently we have made it pearson correlation but it can be cosine\n",
    "    \n",
    "    1 - spatial.distance.cosine(vector1, vector2)\n",
    "    '''\n",
    "    similarity_value = round(pcor(vector1,vector2)[0][1],3)\n",
    "    return similarity_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "e1525aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_visualizations = False ### when this is set to True, visualizations will be expored. If False, visualizations will only be displayed not exported\n",
    "Data_refresh = 0 \n",
    "\n",
    "# Smoothening_param= 3 ### make it dynamic in code below \n",
    "\n",
    "\n",
    "### if it is set to 1, data processing of all models needs to be done. As is this needs to be set1 when we feel model data need to be updated else 0\n",
    "\n",
    "\n",
    "#### Ignore model List \n",
    "Ignore_model_list  = []\n",
    "\n",
    "Ignore_State_list = ['Illinois', 'Arizona', 'Massachusetts',\n",
    "       'Wisconsin', 'Texas', 'Nebraska', 'Utah', 'Oregon','United States','Washington',\n",
    "       'New York', 'Rhode Island', 'Georgia', 'New Hampshire',\n",
    "       'North Carolina', 'New Jersey', 'Colorado', 'Maryland', 'Nevada',\n",
    "       'Tennessee', 'Hawaii', 'Indiana', 'Kentucky', 'Minnesota',\n",
    "       'Oklahoma', 'Pennsylvania', 'South Carolina',\n",
    "       'District of Columbia', 'Kansas', 'Missouri', 'Vermont',\n",
    "       'Virginia', 'Connecticut', 'Iowa', 'Louisiana', 'Ohio', 'Michigan',\n",
    "       'South Dakota', 'Arkansas', 'Delaware', 'Mississippi',\n",
    "       'New Mexico', 'North Dakota', 'Wyoming', 'Alaska', 'Maine',\n",
    "       'Alabama', 'Idaho', 'Montana', 'Puerto Rico', 'Virgin Islands',\n",
    "       'Guam', 'West Virginia', 'Northern Mariana Islands',\n",
    "       'American Samoa']\n",
    "\n",
    "# select_state_list = [\"Florida\"]\n",
    "\n",
    "# State_list = [\"Florida\"]\n",
    "\n",
    "\n",
    "vector_length = (0,4)   ### 1 means using N-1 week value for defining shapelet and 4 weeks 4 weeks from future. 4 can't be changed because models generate only 4 weeks ahead predictions.\n",
    "## (0,4) means look 4 weeks ahead in future while defining shapelet\n",
    "## (1,4) means look 4 weeks ahead in future, 1 week in past basically N-1 week from actual covid incidence list for defining shapelet\n",
    "\n",
    "history_weeks = vector_length[0]\n",
    "\n",
    "future_weeks = vector_length[1]\n",
    "\n",
    "assert future_weeks<=4,\"Looking 4 weeks in future is fixed because our modelsgenerate 4 weeks ahead predictions. \\n Please change vector_length[1]\"\n",
    "\n",
    "\n",
    "# Hyper Params \n",
    "\n",
    "Number_of_shapelets = 2 ### 6 \n",
    "\n",
    "global Shapelet_length\n",
    "Shapelet_length = vector_length[0]+vector_length[1]\n",
    "\n",
    "shapelet_standard_array = [[0]*Shapelet_length for w in range(Number_of_shapelets)]\n",
    "## here we have initialized an zero valued array of array.\n",
    "\n",
    "#shapelet_standard_names = [\"Flat\",\"Inc\",'Dec',\"Surge\",'Peaking',\"Near Peak\"]\n",
    "shapelet_standard_names = [\"Inc\",'Dec']\n",
    "assert len(shapelet_standard_names)==Number_of_shapelets, 'Size of array mismatch for shapelet_standard_names and value of  Number_of_shapelets'\n",
    "# print('Size Mismacth')\n",
    "\n",
    "### for this experiment, we have defined following shapelets \n",
    "# flat = [1.0, 1.00000001, 1.00000002, 1.00000003, 1.00000004]\n",
    "# stable_inc = [1 ,2, 3, 4, 5]#, i.e., linear\n",
    "# stable_dec = [5, 4, 3 ,2, 1]#, i.e., linear but decreasing\n",
    "# surge =[exp(-1/2), exp(0/2), exp(1/2), exp(2/2), exp(3/2)]#, i.e., like exp(x)\n",
    "# peaking = [-1*w for w in [exp(1/2) ,exp(0/2), exp(-1/2), exp(-2/2), exp(-3/2)]]#, i.e., like -exp(-x)\n",
    "# at_near_peak=  [-1*w for w in [exp(-1/2) ,exp(0/2) ,exp(1/2) ,exp(2/2), exp(3/2)]]#, i.e., like -exp(x)\n",
    "\n",
    "# shapelet_standard_array[0] = [1.0, 0, 1.0, 0.0000,1]\n",
    "shapelet_standard_array[0] = [1 ,2, 3, 4]\n",
    "shapelet_standard_array[1] = [5, 4, 3 ,2]\n",
    "# shapelet_standard_array[3] = [1,2,4,8,16]\n",
    "# shapelet_standard_array[4] = [-1*w for w in [exp(1/2) ,exp(0/2), exp(-1/2), exp(-2/2),exp(-3/2)]]\n",
    "# shapelet_standard_array[5] = [-1*w for w in [exp(-1/2) ,exp(0/2) ,exp(1/2) ,exp(2/2),exp(3/2)]]\n",
    "\n",
    "assert len(shapelet_standard_array[0])==Shapelet_length, 'Size of defined shapelet array mismatch for shapelet_standard_names and value of  Shapelet_length.please check vector_length'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import glob\n",
    "\n",
    "def valid_week_nbr(a_string):\n",
    "\n",
    "    if [int(word) for word in a_string.split() if word.isdigit()][0]<5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def interpolate(test_array):\n",
    "    inter_list= []\n",
    "    array_x = [w[0] for w in test_array]\n",
    "    array_y = [w[1] for w in test_array]\n",
    "#     sum_iter = 0\n",
    "    for i in range(50):\n",
    "        value_x = np.random.uniform(low=0.0, high=1.0)\n",
    "        y_inter = np.interp(value_x,array_x,array_y)\n",
    "        inter_list.append(round(y_inter,2))\n",
    "    return inter_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df40b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e57c4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source_path = \"../Data_Sources/quantile_preprocessing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "11d6d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "locatoins = pd.read_csv(Source_path+\"locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "f910fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_mapping = locatoins[['location','location_name']].set_index(\"location\").to_dict()['location_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "413e1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'CEID-Walk'\n",
    "\n",
    "runtype = \"case\"\n",
    "\n",
    "valid_vals = ['US',\t '01',\t '02',\t '04',\t '05',\t '06',\t '08',\t '09',\t '10',\t '11',\t '12',\t '13',\t '15',\t '16',\t '17',\t '18',\t '19',\t '20',\t '21',\t '22',\t '23',\t '24',\t '25',\t '26',\t '27',\t '28',\t '29',\t '30',\t '31',\t '32',\t '33',\t '34',\t '35',\t '36',\t '37',\t '38',\t '39',\t '40',\t '41',\t '42',\t '44',\t '45',\t '46',\t '47',\t '48',\t '49',\t '50',\t '51',\t '53',\t '54',\t '55',\t '56',\t '60',\t '66',\t '69',\t '72',\t '74',\t '78']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bc6608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "0fd8d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Source_path+\"2020-08-09-CEID-Walk.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8eedf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_csv(Source_path+\"2020-08-09-CEID-Walk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "f17fb168",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/satwant/Downloads/CEID-Walk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "47a691df",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(path+\"2*.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "73a6922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-514-86d49c88e514>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cases_data['location'] = cases_data['location'].apply(lambda x : location_mapping.get(x,x))\n",
      "<ipython-input-514-86d49c88e514>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cases_data['valid_row'] = cases_data['target'].apply(valid_week_nbr)\n"
     ]
    }
   ],
   "source": [
    "master_data = pd.DataFrame()\n",
    "for i in filenames:\n",
    "    tmp = pd.read_csv(i)\n",
    "    ## filter for runtype\n",
    "    cases_data_tmp = tmp[tmp['target'].str.contains(runtype)]\n",
    "\n",
    "    ## filter for quantiles only \n",
    "\n",
    "    cases_data_tmp1 = cases_data_tmp[cases_data_tmp['type']=='quantile']\n",
    "\n",
    "    cases_data = cases_data_tmp1[cases_data_tmp1['location'].isin(valid_vals)]\n",
    "\n",
    "    cases_data['location'] = cases_data['location'].apply(lambda x : location_mapping.get(x,x)) \n",
    "\n",
    "    cases_data['valid_row'] = cases_data['target'].apply(valid_week_nbr)\n",
    "\n",
    "    cases_data = cases_data[cases_data['valid_row']==1]\n",
    "    \n",
    "    master_data = pd.concat([master_data,cases_data],axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "6e17ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_data = master_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "9d89f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_data['ordered_pair'] =cases_data[['quantile', 'value']].apply(tuple, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "22fcb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_subset = cases_data[['forecast_date','location','target','ordered_pair','target_end_date']]\n",
    "\n",
    "\n",
    "cases_rolledup = cases_subset.groupby(['forecast_date','location','target','target_end_date'])['ordered_pair'].apply(list).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "aeb61ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "c5cade32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup['IR_value_50sim'] = cases_rolledup['ordered_pair'].apply(interpolate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "6a64976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup['week_interpolated_array'] =cases_rolledup[['target', 'IR_value_50sim']].apply(tuple, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "99a9bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1 = cases_rolledup.groupby(['forecast_date','location'])['week_interpolated_array'].apply(list).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "9b145324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_Similarity_score_all(x):\n",
    "    try:\n",
    "    #     print(x[0][0])\n",
    "    #     frst_week = []\n",
    "        for item in x:\n",
    "            if item[0].find(\"1\")>-1:\n",
    "                frst_week=item[1]\n",
    "                break\n",
    "        second_week = []\n",
    "        for item in x:\n",
    "            if item[0].find(\"2\")>-1:\n",
    "                second_week=item[1]\n",
    "                break\n",
    "        thrd_week =[]\n",
    "        for item in x:\n",
    "            if item[0].find(\"3\")>-1:\n",
    "                thrd_week=item[1]\n",
    "                break\n",
    "        frth_week=[]\n",
    "        for item in x:\n",
    "            if item[0].find(\"4\")>-1:\n",
    "                frth_week=item[1]\n",
    "                break\n",
    "        interpolated_array = []\n",
    "\n",
    "\n",
    "        for i in range(len(frst_week)):\n",
    "            vector = [frst_week[i],second_week[i],thrd_week[i],frth_week[i]]\n",
    "    #         print(vector)\n",
    "            interpolated_array.append(return_all_shapelet_pearson(vector))\n",
    "\n",
    "\n",
    "        return interpolated_array\n",
    "    except:\n",
    "        return \"NAN\"\n",
    "    \n",
    "def aggregated_similarity(data):\n",
    "    try:\n",
    "        a = np.array(data)\n",
    "\n",
    "        aggs = a.mean(axis=0)\n",
    "\n",
    "        xx = [round(w,4) for w in aggs]\n",
    "        return xx\n",
    "    except:\n",
    "        print(data)\n",
    "    \n",
    "from datetime import date\n",
    "\n",
    "\n",
    "d0 = date(2020, 1, 22)\n",
    "\n",
    "def format_dt_int(w):\n",
    "    wsplit = w.split(\"-\")\n",
    "    yr = int(wsplit[0])\n",
    "    mth=int(wsplit[1])\n",
    "    dt = int(wsplit[2])\n",
    "    d1 = date(yr, mth, dt)\n",
    "    delta = d1 - d0\n",
    "    return delta.days\n",
    "\n",
    "import math\n",
    "def is_valid(x):\n",
    "    for i in x:\n",
    "        if math.isnan(i):\n",
    "            return 0\n",
    "    return 1             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "e9fe2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cases_rolledup1['All_iterpol_similar'] = cases_rolledup1['week_interpolated_array'].apply(return_Similarity_score_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "12105fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1 = cases_rolledup1[cases_rolledup1['All_iterpol_similar']!='NAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "a4dc01be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-543-84d599ac45d6>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cases_rolledup1['aggregated_similarity'] = cases_rolledup1['All_iterpol_similar'].apply(aggregated_similarity)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cases_rolledup1['aggregated_similarity'] = cases_rolledup1['All_iterpol_similar'].apply(aggregated_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "db558481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-546-ef84189f3f49>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cases_rolledup1['forecast_date1'] = cases_rolledup1['forecast_date'].apply(format_dt_int)\n"
     ]
    }
   ],
   "source": [
    "cases_rolledup1['forecast_date1'] = cases_rolledup1['forecast_date'].apply(format_dt_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "88575757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-547-e3a45e6bf7ca>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cases_rolledup1['model_name'] = model_name\n"
     ]
    }
   ],
   "source": [
    "cases_rolledup1['model_name'] = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "c3d64a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_rolledup1_subset = cases_rolledup1[['model_name','forecast_date1','location','aggregated_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "b51a85b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-551-67fb048b22af>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cases_rolledup1_subset['valid_row'] = cases_rolledup1_subset['aggregated_similarity'].apply(is_valid)\n"
     ]
    }
   ],
   "source": [
    "cases_rolledup1_subset['valid_row'] = cases_rolledup1_subset['aggregated_similarity'].apply(is_valid)\n",
    "\n",
    "cases_rolledup1_subset = cases_rolledup1_subset[cases_rolledup1_subset[\"valid_row\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "2fa7a100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>forecast_date1</th>\n",
       "      <th>location</th>\n",
       "      <th>aggregated_similarity</th>\n",
       "      <th>valid_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>200</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>[-0.1308, 0.1308]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>200</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>[0.0851, -0.0851]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>[0.0404, -0.0404]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>200</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>[0.0632, -0.0632]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>200</td>\n",
       "      <td>California</td>\n",
       "      <td>[0.343, -0.343]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>838</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>[-0.0418, 0.0418]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>838</td>\n",
       "      <td>Washington</td>\n",
       "      <td>[0.0081, -0.0081]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>838</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>[-0.0595, 0.0595]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>838</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>[0.1043, -0.1043]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>838</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>[0.0535, -0.0535]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3556 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  forecast_date1       location aggregated_similarity  \\\n",
       "0     CEID-Walk             200        Alabama     [-0.1308, 0.1308]   \n",
       "1     CEID-Walk             200         Alaska     [0.0851, -0.0851]   \n",
       "3     CEID-Walk             200        Arizona     [0.0404, -0.0404]   \n",
       "4     CEID-Walk             200       Arkansas     [0.0632, -0.0632]   \n",
       "5     CEID-Walk             200     California       [0.343, -0.343]   \n",
       "...         ...             ...            ...                   ...   \n",
       "3757  CEID-Walk             838       Virginia     [-0.0418, 0.0418]   \n",
       "3758  CEID-Walk             838     Washington     [0.0081, -0.0081]   \n",
       "3759  CEID-Walk             838  West Virginia     [-0.0595, 0.0595]   \n",
       "3760  CEID-Walk             838      Wisconsin     [0.1043, -0.1043]   \n",
       "3761  CEID-Walk             838        Wyoming     [0.0535, -0.0535]   \n",
       "\n",
       "      valid_row  \n",
       "0             1  \n",
       "1             1  \n",
       "3             1  \n",
       "4             1  \n",
       "5             1  \n",
       "...         ...  \n",
       "3757          1  \n",
       "3758          1  \n",
       "3759          1  \n",
       "3760          1  \n",
       "3761          1  \n",
       "\n",
       "[3556 rows x 5 columns]"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_rolledup1_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "b5610b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapelet_ensemble = [round(w,4) for w in \\\n",
    "#                      list(np.array(cases_rolledup1_subset['aggregated_similarity'].to_list()).mean(axis=0))]\n",
    "                     \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "7166e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapelet_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1cdbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c7c85764",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = cases_rolledup.pivot(index=['forecast_date','location'], columns='target_end_date', values='IR_value_50sim').reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "673a429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = processed_df.forecast_date.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2c829b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.replace(current_date,\"NaN\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1df0cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = list(processed_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e1ab677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.columns = [current_date]+[original_columns[1]]+original_columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "43d41c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df_final = processed_df[[original_columns[1]]+[current_date]+original_columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e5e794cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>2020-08-09</th>\n",
       "      <th>2020-08-15</th>\n",
       "      <th>2020-08-22</th>\n",
       "      <th>2020-08-29</th>\n",
       "      <th>2020-09-05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10063.472173</td>\n",
       "      <td>10067.909694</td>\n",
       "      <td>9931.869003</td>\n",
       "      <td>9827.519538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.476641</td>\n",
       "      <td>104.130352</td>\n",
       "      <td>107.947853</td>\n",
       "      <td>115.464909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>484.352074</td>\n",
       "      <td>416.586318</td>\n",
       "      <td>447.520027</td>\n",
       "      <td>468.479518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.453318</td>\n",
       "      <td>17.391378</td>\n",
       "      <td>15.118307</td>\n",
       "      <td>21.016704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.969214</td>\n",
       "      <td>65.559894</td>\n",
       "      <td>65.205716</td>\n",
       "      <td>63.618655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.058448</td>\n",
       "      <td>54.910670</td>\n",
       "      <td>50.342924</td>\n",
       "      <td>51.444087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.185623</td>\n",
       "      <td>3.814157</td>\n",
       "      <td>4.110112</td>\n",
       "      <td>4.133898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3542.295718</td>\n",
       "      <td>3457.178047</td>\n",
       "      <td>3553.352069</td>\n",
       "      <td>3502.905559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.090125</td>\n",
       "      <td>123.443248</td>\n",
       "      <td>97.755159</td>\n",
       "      <td>129.874003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>370910.027943</td>\n",
       "      <td>385625.294584</td>\n",
       "      <td>399655.583194</td>\n",
       "      <td>370297.089693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3198 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location 2020-08-09     2020-08-15     2020-08-22     2020-08-29  \\\n",
       "0          01        NaN   10063.472173   10067.909694    9931.869003   \n",
       "1       01001        NaN      96.476641     104.130352     107.947853   \n",
       "2       01003        NaN     484.352074     416.586318     447.520027   \n",
       "3       01005        NaN      26.453318      17.391378      15.118307   \n",
       "4       01007        NaN      63.969214      65.559894      65.205716   \n",
       "...       ...        ...            ...            ...            ...   \n",
       "3193       66        NaN      57.058448      54.910670      50.342924   \n",
       "3194       69        NaN       4.185623       3.814157       4.110112   \n",
       "3195       72        NaN    3542.295718    3457.178047    3553.352069   \n",
       "3196       78        NaN     111.090125     123.443248      97.755159   \n",
       "3197       US        NaN  370910.027943  385625.294584  399655.583194   \n",
       "\n",
       "         2020-09-05  \n",
       "0       9827.519538  \n",
       "1        115.464909  \n",
       "2        468.479518  \n",
       "3         21.016704  \n",
       "4         63.618655  \n",
       "...             ...  \n",
       "3193      51.444087  \n",
       "3194       4.133898  \n",
       "3195    3502.905559  \n",
       "3196     129.874003  \n",
       "3197  370297.089693  \n",
       "\n",
       "[3198 rows x 6 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a37225",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1) Location column mapping and filters<br><br>  locations.csv in data folder\n",
    "2) Aggregation criterion for multiple iterations of interpolation<br><br>\n",
    "3) should we keep same code by just adding a hyper param which runs the\n",
    "interpolation preprocessing script and changes visualization titles to (Quantile)?<br><br>\n",
    "4) From Washington, California, Florida, 2 clusters pretty evident . so need to decide if we want to reduce # of shapes<br><br>\n",
    "5) Research paper next steps as deadlines approaching<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d587829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d4b819d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = list(processed_df_final.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "be123657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22 00:00:00\n",
      "2020-08-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# N = 200\n",
    "# t = '2020-01-22'\n",
    "# format = '%Y-%m-%d'\n",
    "# now = datetime.strptime(t,format)\n",
    "# after = now + timedelta(days = N)\n",
    "# print(now)\n",
    "# print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4e5a34e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "206\n",
      "213\n",
      "220\n",
      "227\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "new_columns = []\n",
    "\n",
    "d0 = date(2020, 1, 22)\n",
    "\n",
    "for w in date_columns:\n",
    "    wsplit = w.split(\"-\")\n",
    "    yr = int(wsplit[0])\n",
    "    mth=int(wsplit[1])\n",
    "    dt = int(wsplit[2])\n",
    "    d1 = date(yr, mth, dt)\n",
    "    delta = d1 - d0\n",
    "    print(delta.days)\n",
    "    new_columns.append(delta.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6c47702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df_final.columns = [list(processed_df_final.columns)[0]]+new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "dbb46a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>200</th>\n",
       "      <th>206</th>\n",
       "      <th>213</th>\n",
       "      <th>220</th>\n",
       "      <th>227</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10063.472173</td>\n",
       "      <td>10067.909694</td>\n",
       "      <td>9931.869003</td>\n",
       "      <td>9827.519538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.476641</td>\n",
       "      <td>104.130352</td>\n",
       "      <td>107.947853</td>\n",
       "      <td>115.464909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>484.352074</td>\n",
       "      <td>416.586318</td>\n",
       "      <td>447.520027</td>\n",
       "      <td>468.479518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.453318</td>\n",
       "      <td>17.391378</td>\n",
       "      <td>15.118307</td>\n",
       "      <td>21.016704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.969214</td>\n",
       "      <td>65.559894</td>\n",
       "      <td>65.205716</td>\n",
       "      <td>63.618655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location  200           206           213          220          227\n",
       "0       01  NaN  10063.472173  10067.909694  9931.869003  9827.519538\n",
       "1    01001  NaN     96.476641    104.130352   107.947853   115.464909\n",
       "2    01003  NaN    484.352074    416.586318   447.520027   468.479518\n",
       "3    01005  NaN     26.453318     17.391378    15.118307    21.016704\n",
       "4    01007  NaN     63.969214     65.559894    65.205716    63.618655"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebec5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
