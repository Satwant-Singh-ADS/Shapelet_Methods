{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be2f7c5",
   "metadata": {},
   "source": [
    "# Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b24b83",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/curve-fitting-with-python/\n",
    "\n",
    "https://study.com/academy/lesson/interpolation-in-statistics-definition-formula-example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdee0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numpy import corrcoef as pcor\n",
    "\n",
    "from numpy import exp as exp\n",
    "from scipy import spatial\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import glob\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def return_best_shapelet_pearson(vector):\n",
    "    correlation_lst = []\n",
    "    corrs = []\n",
    "    for i in range(len(shapelet_standard_array)):\n",
    "        score = similarity_metrix(shapelet_standard_array[i],vector)\n",
    "        correlation_lst.append(shapelet_standard_names[i])\n",
    "        corrs.append(score)\n",
    "    scenario = corrs.index(max(corrs))\n",
    "    return correlation_lst[scenario]\n",
    "\n",
    "    \n",
    "def return_all_shapelet_pearson(vector):\n",
    "#     correlation_lst = []\n",
    "    corrs = []\n",
    "    for i in range(len(shapelet_standard_array)):\n",
    "        score = similarity_metrix(shapelet_standard_array[i],vector)\n",
    "#         correlation_lst.append(shapelet_standard_names[i])\n",
    "        corrs.append(score)\n",
    "    return corrs\n",
    "\n",
    "\n",
    "\n",
    "def similarity_metrix(vector1,vector2):\n",
    "    '''\n",
    "    Here we have given user the flexibility to change the similarity function. Currently we have made it pearson correlation but it can be cosine\n",
    "    \n",
    "    1 - spatial.distance.cosine(vector1, vector2)\n",
    "    '''\n",
    "    similarity_value = round(pcor(vector1,vector2)[0][1],3)\n",
    "    return similarity_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "280c60c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process will run for Cases\n"
     ]
    }
   ],
   "source": [
    "Runtype = \"Cases\"#### choose Deaths for generating results for deaths and Cases for generating case results\n",
    "\n",
    "if Runtype =='Cases':\n",
    "    print(\"Process will run for Cases\")\n",
    "\n",
    "    Input_path = '../Data_Sources/Cases/'\n",
    "\n",
    "    Ouput_path = '../Data_Sources/Cases/Output_Files/'\n",
    "\n",
    "    Actual_incidence_path = Input_path+\"/Input_Files/Actual_Incidence_Data/\"\n",
    "\n",
    "    pickle_path = Input_path+\"Pickle_Objects/\"\n",
    "\n",
    "    Visualization_path = Input_path+\"Visualizations/\"\n",
    "else:\n",
    "    print(\"Process will run for Deaths\")\n",
    "    Input_path = '../Data_Sources/Deaths/'\n",
    "\n",
    "    Ouput_path = '../Data_Sources/Deaths/Output_Files/'\n",
    "\n",
    "    Actual_incidence_path = Input_path+\"/Input_Files/Actual_Incidence_Data/\"\n",
    "\n",
    "    pickle_path = Input_path+\"Pickle_Objects/\"\n",
    "\n",
    "    Visualization_path = Input_path+\"Visualizations/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0369a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_visualizations = False ### when this is set to True, visualizations will be expored. If False, visualizations will only be displayed not exported\n",
    "Data_refresh = 0 \n",
    "\n",
    "# Smoothening_param= 3 ### make it dynamic in code below \n",
    "\n",
    "\n",
    "### if it is set to 1, data processing of all models needs to be done. As is this needs to be set1 when we feel model data need to be updated else 0\n",
    "\n",
    "\n",
    "#### Ignore model List \n",
    "Ignore_model_list  = []\n",
    "\n",
    "Ignore_State_list = ['Illinois', 'Arizona', 'Massachusetts',\n",
    "       'Wisconsin', 'Texas', 'Nebraska', 'Utah', 'Oregon','United States','Washington',\n",
    "       'New York', 'Rhode Island', 'Georgia', 'New Hampshire',\n",
    "       'North Carolina', 'New Jersey', 'Colorado', 'Maryland', 'Nevada',\n",
    "       'Tennessee', 'Hawaii', 'Indiana', 'Kentucky', 'Minnesota',\n",
    "       'Oklahoma', 'Pennsylvania', 'South Carolina',\n",
    "       'District of Columbia', 'Kansas', 'Missouri', 'Vermont',\n",
    "       'Virginia', 'Connecticut', 'Iowa', 'Louisiana', 'Ohio', 'Michigan',\n",
    "       'South Dakota', 'Arkansas', 'Delaware', 'Mississippi',\n",
    "       'New Mexico', 'North Dakota', 'Wyoming', 'Alaska', 'Maine',\n",
    "       'Alabama', 'Idaho', 'Montana', 'Puerto Rico', 'Virgin Islands',\n",
    "       'Guam', 'West Virginia', 'Northern Mariana Islands',\n",
    "       'American Samoa']\n",
    "\n",
    "# select_state_list = [\"Florida\"]\n",
    "\n",
    "# State_list = [\"Florida\"]\n",
    "\n",
    "\n",
    "vector_length = (0,4)   ### 1 means using N-1 week value for defining shapelet and 4 weeks 4 weeks from future. 4 can't be changed because models generate only 4 weeks ahead predictions.\n",
    "## (0,4) means look 4 weeks ahead in future while defining shapelet\n",
    "## (1,4) means look 4 weeks ahead in future, 1 week in past basically N-1 week from actual covid incidence list for defining shapelet\n",
    "\n",
    "history_weeks = vector_length[0]\n",
    "\n",
    "future_weeks = vector_length[1]\n",
    "\n",
    "assert future_weeks<=4,\"Looking 4 weeks in future is fixed because our modelsgenerate 4 weeks ahead predictions. \\n Please change vector_length[1]\"\n",
    "\n",
    "\n",
    "Number_of_shapelets = 6 ### 6 \n",
    "\n",
    "global Shapelet_length\n",
    "Shapelet_length = vector_length[0]+vector_length[1]\n",
    "\n",
    "shapelet_standard_array = [[0]*Shapelet_length for w in range(Number_of_shapelets)]\n",
    "## here we have initialized an zero valued array of array.\n",
    "\n",
    "\n",
    "# Hyper Params \n",
    "\n",
    "shapelet_standard_names = [\"Flat\",\"Inc\",'Dec',\"Surge\",'Peaking',\"Near Peak\"]\n",
    "\n",
    "assert len(shapelet_standard_names)==Number_of_shapelets, 'Size of array mismatch for shapelet_standard_names and value of  Number_of_shapelets'\n",
    "# print('Size Mismacth')\n",
    "\n",
    "### for this experiment, we have defined following shapelets \n",
    "# flat = [1.0, 1.00000001, 1.00000002, 1.00000003, 1.00000004]\n",
    "# stable_inc = [1 ,2, 3, 4, 5]#, i.e., linear\n",
    "# stable_dec = [5, 4, 3 ,2, 1]#, i.e., linear but decreasing\n",
    "# surge =[exp(-1/2), exp(0/2), exp(1/2), exp(2/2), exp(3/2)]#, i.e., like exp(x)\n",
    "# peaking = [-1*w for w in [exp(1/2) ,exp(0/2), exp(-1/2), exp(-2/2), exp(-3/2)]]#, i.e., like -exp(-x)\n",
    "# at_near_peak=  [-1*w for w in [exp(-1/2) ,exp(0/2) ,exp(1/2) ,exp(2/2), exp(3/2)]]#, i.e., like -exp(x)\n",
    "\n",
    "shapelet_standard_array[0] = [1.0, 0, 1.0, 0.0000]\n",
    "shapelet_standard_array[1] = [1 ,2, 3, 4]\n",
    "shapelet_standard_array[2] = [5, 4, 3 ,2]\n",
    "shapelet_standard_array[3] = [1,2,4,8]\n",
    "shapelet_standard_array[4] = [-1*w for w in [exp(1/2) ,exp(0/2), exp(-1/2), exp(-2/2)]]\n",
    "shapelet_standard_array[5] = [-1*w for w in [exp(-1/2) ,exp(0/2) ,exp(1/2) ,exp(2/2)]]\n",
    "\n",
    "assert len(shapelet_standard_array[0])==Shapelet_length, 'Size of defined shapelet array mismatch for shapelet_standard_names and value of  Shapelet_length.please check vector_length'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa9210c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def valid_week_nbr(a_string):\n",
    "\n",
    "    if [int(word) for word in a_string.split() if word.isdigit()][0]<5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def interpolate(test_array):\n",
    "    inter_list= []\n",
    "    array_x = [w[0] for w in test_array]\n",
    "    array_y = [w[1] for w in test_array]\n",
    "#     sum_iter = 0\n",
    "    for i in range(10):\n",
    "        value_x = np.random.uniform(low=0.0, high=1.0)\n",
    "        y_inter = np.interp(value_x,array_x,array_y)\n",
    "        inter_list.append(round(y_inter,2))\n",
    "    return inter_list\n",
    "def return_Similarity_score_all(x):\n",
    "    try:\n",
    "    #     print(x[0][0])\n",
    "    #     frst_week = []\n",
    "        for item in x:\n",
    "            if item[0].find(\"1\")>-1:\n",
    "                frst_week=item[1]\n",
    "                break\n",
    "        second_week = []\n",
    "        for item in x:\n",
    "            if item[0].find(\"2\")>-1:\n",
    "                second_week=item[1]\n",
    "                break\n",
    "        thrd_week =[]\n",
    "        for item in x:\n",
    "            if item[0].find(\"3\")>-1:\n",
    "                thrd_week=item[1]\n",
    "                break\n",
    "        frth_week=[]\n",
    "        for item in x:\n",
    "            if item[0].find(\"4\")>-1:\n",
    "                frth_week=item[1]\n",
    "                break\n",
    "        interpolated_array = []\n",
    "\n",
    "\n",
    "        for i in range(len(frst_week)):\n",
    "            vector = [frst_week[i],second_week[i],thrd_week[i],frth_week[i]]\n",
    "    #         print(vector)\n",
    "            interpolated_array.append(return_all_shapelet_pearson(vector))\n",
    "\n",
    "\n",
    "        return interpolated_array\n",
    "    except:\n",
    "        return \"NAN\"\n",
    "    \n",
    "def aggregated_similarity(data):\n",
    "    try:\n",
    "        a = np.array(data)\n",
    "\n",
    "        aggs = a.mean(axis=0)\n",
    "\n",
    "        xx = [round(w,4) for w in aggs]\n",
    "        return xx\n",
    "    except:\n",
    "        print(data)\n",
    "    \n",
    "from datetime import date\n",
    "\n",
    "\n",
    "d0 = date(2020, 1, 22)\n",
    "\n",
    "def format_dt_int(w):\n",
    "    wsplit = w.split(\"-\")\n",
    "    yr = int(wsplit[0])\n",
    "    mth=int(wsplit[1])\n",
    "    dt = int(wsplit[2])\n",
    "    d1 = date(yr, mth, dt)\n",
    "    delta = d1 - d0\n",
    "    return delta.days\n",
    "\n",
    "import math\n",
    "def is_valid(x):\n",
    "    for i in x:\n",
    "        if math.isnan(i):\n",
    "            return 0\n",
    "    return 1             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4748911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source_path = \"../Data_Sources/quantile_preprocessing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ed0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "locatoins = pd.read_csv(Source_path+\"locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b667e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_mapping = locatoins[['location','location_name']].set_index(\"location\").to_dict()['location_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f8f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_mapping['US']='United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5561ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'CEID-Walk'\n",
    "\n",
    "runtype = \"case\"\n",
    "\n",
    "valid_vals = ['US',\t '01',\t '02',\t '04',\t '05',\t '06',\t '08',\t '09',\t '10',\t '11',\t '12',\t '13',\t '15',\t '16',\t '17',\t '18',\t '19',\t '20',\t '21',\t '22',\t '23',\t '24',\t '25',\t '26',\t '27',\t '28',\t '29',\t '30',\t '31',\t '32',\t '33',\t '34',\t '35',\t '36',\t '37',\t '38',\t '39',\t '40',\t '41',\t '42',\t '44',\t '45',\t '46',\t '47',\t '48',\t '49',\t '50',\t '51',\t '53',\t '54',\t '55',\t '56',\t '60',\t '66',\t '69',\t '72',\t '74',\t '78']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc6608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "498c90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = Source_path+\"2020-08-09-CEID-Walk.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eedf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = pd.read_csv(Source_path+\"2020-08-09-CEID-Walk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e689dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/Users/satwant/Downloads/CEID-Walk/\"\n",
    "\n",
    "root = '/Users/satwant/Downloads/covid19-forecast-hub-master/data-processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae417497",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = glob.glob(root+\"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a7c7d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UCSB-ACTS'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_root[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39258856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9cf579f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/satwant/Downloads/covid19-forecast-hub-master/data-processed/UCSB-ACTS'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c1ff497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name UCSB-ACTS\n",
      "NEXT\n",
      "Model Name OliverWyman-Navigator\n",
      "NEXT\n",
      "Model Name JHUAPL-Bucky\n",
      "NEXT\n",
      "Model Name DDS-NBDS\n",
      "NEXT\n",
      "Model Name BPagano-RtDriven\n",
      "NEXT\n",
      "Model Name JBUD-HMXK\n",
      "NEXT\n",
      "Model Name UVA-Ensemble\n",
      "NEXT\n",
      "Model Name Microsoft-DeepSTIA\n",
      "NEXT\n",
      "Model Name CU-nochange\n",
      "NEXT\n",
      "Model Name RobertWalraven-ESG\n",
      "NEXT\n",
      "Model Name Covid19Sim-Simulator\n",
      "NEXT\n",
      "Model Name COVIDhub-4_week_ensemble\n",
      "NEXT\n",
      "Model Name CovidAnalytics-DELPHI\n",
      "NEXT\n",
      "Model Name MOBS-GLEAM_COVID\n",
      "NEXT\n",
      "Model Name UCM_MESALab-FoGSEIR\n",
      "NEXT\n",
      "Model Name CovidActNow-SEIR_CAN\n",
      "NEXT\n",
      "Model Name CDDEP-SEIR_MCMC\n",
      "NEXT\n",
      "Model Name LNQ-ens1\n",
      "NEXT\n",
      "Model Name SigSci-TS\n",
      "NEXT\n",
      "Model Name FAIR-NRAR\n",
      "NEXT\n",
      "Model Name GT-DeepCOVID\n",
      "NEXT\n",
      "Model Name USF-STPM\n",
      "NEXT\n",
      "Model Name CU-scenario_mid\n",
      "NEXT\n",
      "Model Name JHUAPL-Gecko\n",
      "NEXT\n",
      "Model Name Geneva-DetGrowth\n",
      "NEXT\n",
      "Model Name UCF-AEM\n",
      "NEXT\n",
      "Model Name MUNI-VAR\n",
      "NEXT\n",
      "Model Name USACE-ERDC_SEIR\n",
      "NEXT\n",
      "Model Name Yu_Group-CLEP\n",
      "NEXT\n",
      "Model Name NotreDame-FRED\n",
      "NEXT\n",
      "Model Name UMass-trends_ensemble\n",
      "NEXT\n",
      "Model Name RPI_UW-Mob_Collision\n",
      "NEXT\n",
      "Model Name CMU-TimeSeries\n",
      "NEXT\n",
      "Model Name MUNI-ARIMA\n",
      "NEXT\n",
      "Model Name UChicago-CovidIL_30_+\n",
      "NEXT\n",
      "Model Name NotreDame-mobility\n",
      "NEXT\n",
      "Model Name SDSC_ISG-TrendModel\n",
      "NEXT\n",
      "Model Name MIT_CritData-GBCF\n",
      "NEXT\n",
      "Model Name Imperial-ensemble1\n",
      "NEXT\n",
      "Model Name UT-Osiris\n",
      "NEXT\n",
      "Model Name Auquan-SEIR\n",
      "NEXT\n",
      "Model Name STH-3PU\n",
      "NEXT\n",
      "Model Name LANL-GrowthRate\n",
      "NEXT\n",
      "Model Name LosAlamos_NAU-CModel_SDVaxVar\n",
      "NEXT\n",
      "Model Name SWC-TerminusCM\n",
      "NEXT\n",
      "Model Name Google_Harvard-CPF\n",
      "NEXT\n",
      "Model Name UChicago-CovidIL_40\n",
      "NEXT\n",
      "Model Name NCSU-COVSIM\n",
      "NEXT\n",
      "Model Name TTU-squider\n",
      "NEXT\n",
      "Model Name CU-scenario_low\n",
      "NEXT\n",
      "Model Name COVIDhub_CDC-ensemble\n",
      "NEXT\n",
      "Model Name UT_GISAG-SPDM\n",
      "NEXT\n",
      "Model Name HKUST-DNN\n",
      "NEXT\n",
      "Model Name CUB_PopCouncil-SLSTM\n",
      "NEXT\n",
      "Model Name UA-EpiCovDA\n",
      "NEXT\n",
      "Model Name QJHong-Encounter\n",
      "NEXT\n",
      "Model Name Karlen-pypm\n",
      "NEXT\n",
      "Model Name PandemicCentral-COVIDForest\n",
      "NEXT\n",
      "Model Name CEID-Walk\n",
      "NEXT\n",
      "Model Name CUBoulder-COVIDLSTM\n",
      "NEXT\n",
      "Model Name Columbia_UNC-SurvCon\n",
      "NEXT\n",
      "Model Name UT-Mobility\n",
      "NEXT\n",
      "Model Name PSI-DICE\n",
      "NEXT\n",
      "Model Name LUcompUncertLab-VAR_3streams\n",
      "NEXT\n",
      "Model Name IBF-TimeSeries\n",
      "NEXT\n",
      "Model Name WalmartLabsML-LogForecasting\n",
      "NEXT\n",
      "Model Name PandemicCentral-USCounty\n",
      "NEXT\n",
      "Model Name Quantori-Multiagents\n",
      "NEXT\n",
      "Model Name FDANIHASU-Sweight\n",
      "NEXT\n",
      "Model Name MIT_ISOLAT-Mixtures\n",
      "NEXT\n",
      "Model Name Wadhwani_AI-BayesOpt\n",
      "NEXT\n",
      "Model Name Caltech-CS156\n",
      "NEXT\n",
      "Model Name IUPUI-HkPrMobiDyR\n",
      "NEXT\n",
      "Model Name JHU_IDD-CovidSP\n",
      "NEXT\n",
      "Model Name KITmetricslab-select_ensemble\n",
      "NEXT\n",
      "Model Name UCLA-SuEIR\n",
      "NEXT\n",
      "Model Name CU-scenario_high\n",
      "NEXT\n",
      "Model Name COVIDhub-trained_ensemble\n",
      "NEXT\n",
      "Model Name SteveMcConnell-CovidComplete\n",
      "NEXT\n",
      "Model Name JHUAPL-SLPHospEns\n",
      "NEXT\n",
      "Model Name JHU_UNC_GAS-StatMechPool\n",
      "NEXT\n",
      "Model Name YYG-ParamSearch\n",
      "NEXT\n",
      "Model Name IowaStateLW-STEM\n",
      "NEXT\n",
      "Model Name MSRA-DeepST\n",
      "NEXT\n",
      "Model Name UChicago-CovidIL_10_+\n",
      "NEXT\n",
      "Model Name MIT-Cassandra\n",
      "NEXT\n",
      "Model Name UMass-ExpertCrowd\n",
      "NEXT\n",
      "Model Name MITCovAlliance-SIR\n",
      "NEXT\n",
      "Model Name UpstateSU-GRU\n",
      "NEXT\n",
      "Model Name prolix-euclidean\n",
      "NEXT\n",
      "Model Name COVIDhub-ensemble\n",
      "NEXT\n",
      "Model Name UMass-sarix\n",
      "NEXT\n",
      "Model Name USC-SI_kJalpha\n",
      "NEXT\n",
      "Model Name ISUandPKU-vSEIdR\n",
      "Model Name UChicago-CovidIL_100\n",
      "NEXT\n",
      "Model Name UChicago-CovidIL_60\n",
      "NEXT\n",
      "Model Name UMich-RidgeTfReg\n",
      "NEXT\n",
      "Model Name UMass-MechBayes\n",
      "NEXT\n",
      "Model Name UChicago-CovidIL_80\n",
      "NEXT\n",
      "Model Name epiforecasts-ensemble1\n",
      "NEXT\n",
      "Model Name IQVIA_ACOE-STAN\n",
      "NEXT\n",
      "Model Name COVIDhub-baseline\n",
      "NEXT\n",
      "Model Name UChicagoCHATTOPADHYAY-UnIT\n",
      "NEXT\n",
      "Model Name USC-SI_kJalpha_RF\n",
      "NEXT\n",
      "Model Name IHME-CurveFit\n",
      "NEXT\n",
      "Model Name UChicago-CovidIL\n",
      "NEXT\n",
      "Model Name UCSD_NEU-DeepGLEAM\n",
      "NEXT\n",
      "Model Name Imperial-ensemble2\n",
      "NEXT\n",
      "Model Name CWRU-COVID_19Predict\n",
      "NEXT\n",
      "Model Name OneQuietNight-ML\n",
      "NEXT\n",
      "Model Name IEM_MED-CovidProject\n",
      "NEXT\n",
      "Model Name JHU_CSSE-DECOM\n",
      "NEXT\n",
      "Model Name AIpert-pwllnod\n",
      "NEXT\n",
      "Model Name GT_CHHS-COVID19\n",
      "NEXT\n",
      "Model Name JCB-PRM\n",
      "NEXT\n",
      "Model Name CU-select\n",
      "NEXT\n",
      "Model Name PSI-DRAFT\n",
      "NEXT\n",
      "Model Name FRBSF_Wilson-Econometric\n",
      "NEXT\n"
     ]
    }
   ],
   "source": [
    "model_master_df = pd.DataFrame()\n",
    "except_list = []\n",
    "for path in model_root:\n",
    "    try:\n",
    "        model_name = path.split(\"/\")[-1]\n",
    "        if model_name in Ignore_model_list:\n",
    "            continue\n",
    "        print(\"Model Name\",model_name)\n",
    "        filenames = glob.glob(path+\"/2*.csv\") \n",
    "        master_data = pd.DataFrame()\n",
    "        for i in filenames:\n",
    "            tmp = pd.read_csv(i)\n",
    "            ## filter for runtype\n",
    "            cases_data_tmp = tmp[tmp['target'].str.contains(runtype)]\n",
    "            cases_data_tmp1 = cases_data_tmp[cases_data_tmp['type']=='quantile']\n",
    "            cases_data = cases_data_tmp1[cases_data_tmp1['location'].isin(valid_vals)]\n",
    "            cases_data['location'] = cases_data['location'].apply(lambda x : location_mapping.get(x,x)) \n",
    "            cases_data = cases_data[~cases_data['location'].isin(Ignore_State_list)]\n",
    "            cases_data['valid_row'] = cases_data['target'].apply(valid_week_nbr)\n",
    "            cases_data = cases_data[cases_data['valid_row']==1]\n",
    "            master_data = pd.concat([master_data,cases_data],axis=0)\n",
    "        cases_data = master_data.copy()\n",
    "        cases_data['ordered_pair'] =cases_data[['quantile', 'value']].apply(tuple, axis=1)\n",
    "        cases_subset = cases_data[['forecast_date','location','target','ordered_pair','target_end_date']]\n",
    "        cases_rolledup = cases_subset.groupby(['forecast_date','location','target','target_end_date'])['ordered_pair'].apply(list).reset_index()\n",
    "        cases_rolledup['IR_value_50sim'] = cases_rolledup['ordered_pair'].apply(interpolate)\n",
    "        cases_rolledup['week_interpolated_array'] =cases_rolledup[['target', 'IR_value_50sim']].apply(tuple, axis=1)\n",
    "        cases_rolledup1 = cases_rolledup.groupby(['forecast_date','location'])['week_interpolated_array'].apply(list).reset_index()\n",
    "        cases_rolledup1['All_iterpol_similar'] = cases_rolledup1['week_interpolated_array'].apply(return_Similarity_score_all)\n",
    "        cases_rolledup1 = cases_rolledup1[cases_rolledup1['All_iterpol_similar']!='NAN']\n",
    "        cases_rolledup1['aggregated_similarity'] = cases_rolledup1['All_iterpol_similar'].apply(aggregated_similarity)\n",
    "        cases_rolledup1['forecast_date1'] = cases_rolledup1['forecast_date'].apply(format_dt_int)\n",
    "        cases_rolledup1['model_name'] = model_name\n",
    "        cases_rolledup1_subset = cases_rolledup1[['forecast_date','model_name','forecast_date1','location','aggregated_similarity']]\n",
    "        cases_rolledup1_subset['valid_row'] = cases_rolledup1_subset['aggregated_similarity'].apply(is_valid)\n",
    "        cases_rolledup1_subset = cases_rolledup1_subset[cases_rolledup1_subset[\"valid_row\"]==1]\n",
    "        model_master_df = pd.concat([model_master_df,cases_rolledup1_subset],axis=0)\n",
    "        print(\"NEXT\")\n",
    "    except:\n",
    "        except_list.append(path)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "819f3d7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>model_name</th>\n",
       "      <th>forecast_date1</th>\n",
       "      <th>location</th>\n",
       "      <th>aggregated_similarity</th>\n",
       "      <th>valid_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>JHUAPL-Bucky</td>\n",
       "      <td>222</td>\n",
       "      <td>California</td>\n",
       "      <td>[-0.0712, 0.1784, -0.1784, 0.2174, 0.1387, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>JHUAPL-Bucky</td>\n",
       "      <td>222</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[0.0436, 0.0122, -0.0122, 0.0256, -0.0015, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>JHUAPL-Bucky</td>\n",
       "      <td>229</td>\n",
       "      <td>California</td>\n",
       "      <td>[0.2501, -0.2355, 0.2355, -0.2313, -0.2348, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>JHUAPL-Bucky</td>\n",
       "      <td>229</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[0.1511, -0.1029, 0.1029, -0.0839, -0.1182, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>JHUAPL-Bucky</td>\n",
       "      <td>236</td>\n",
       "      <td>California</td>\n",
       "      <td>[0.247, -0.6134, 0.6134, -0.5969, -0.5913, 0.6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>CU-select</td>\n",
       "      <td>830</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[-0.2636, 0.7205, -0.7205, 0.6092, 0.7623, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>CU-select</td>\n",
       "      <td>837</td>\n",
       "      <td>California</td>\n",
       "      <td>[-0.3903, 0.8447, -0.8447, 0.7335, 0.8841, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>CU-select</td>\n",
       "      <td>837</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[-0.4688, 0.6621, -0.6621, 0.5847, 0.6957, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>CU-select</td>\n",
       "      <td>844</td>\n",
       "      <td>California</td>\n",
       "      <td>[-0.3659, 0.7019, -0.7019, 0.6195, 0.7297, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>CU-select</td>\n",
       "      <td>844</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[-0.3399, 0.5853, -0.5853, 0.4715, 0.6448, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5174 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    forecast_date    model_name forecast_date1    location  \\\n",
       "0      2020-08-31  JHUAPL-Bucky            222  California   \n",
       "1      2020-08-31  JHUAPL-Bucky            222     Florida   \n",
       "2      2020-09-07  JHUAPL-Bucky            229  California   \n",
       "3      2020-09-07  JHUAPL-Bucky            229     Florida   \n",
       "4      2020-09-14  JHUAPL-Bucky            236  California   \n",
       "..            ...           ...            ...         ...   \n",
       "211    2022-05-01     CU-select            830     Florida   \n",
       "212    2022-05-08     CU-select            837  California   \n",
       "213    2022-05-08     CU-select            837     Florida   \n",
       "214    2022-05-15     CU-select            844  California   \n",
       "215    2022-05-15     CU-select            844     Florida   \n",
       "\n",
       "                                 aggregated_similarity valid_row  \n",
       "0    [-0.0712, 0.1784, -0.1784, 0.2174, 0.1387, -0....         1  \n",
       "1    [0.0436, 0.0122, -0.0122, 0.0256, -0.0015, -0....         1  \n",
       "2    [0.2501, -0.2355, 0.2355, -0.2313, -0.2348, 0....         1  \n",
       "3    [0.1511, -0.1029, 0.1029, -0.0839, -0.1182, 0....         1  \n",
       "4    [0.247, -0.6134, 0.6134, -0.5969, -0.5913, 0.6...         1  \n",
       "..                                                 ...       ...  \n",
       "211  [-0.2636, 0.7205, -0.7205, 0.6092, 0.7623, -0....         1  \n",
       "212  [-0.3903, 0.8447, -0.8447, 0.7335, 0.8841, -0....         1  \n",
       "213  [-0.4688, 0.6621, -0.6621, 0.5847, 0.6957, -0....         1  \n",
       "214  [-0.3659, 0.7019, -0.7019, 0.6195, 0.7297, -0....         1  \n",
       "215  [-0.3399, 0.5853, -0.5853, 0.4715, 0.6448, -0....         1  \n",
       "\n",
       "[5174 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_master_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7192d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_master_df.to_csv(\"Quantile_output_file_cases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37231bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1) Map actual cases Pearson correlation to each row\\n\\n1b) generate shapelet ensemble row at state-week level\\n\\n2) Apply cosine similarity between model and actual cases pearson corr vector\\n\\n3) Visualize\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1) Map actual cases Pearson correlation to each row -- done\n",
    "\n",
    "1b) generate shapelet ensemble row at state-week level \n",
    "\n",
    "2) Apply cosine similarity between model and actual cases pearson corr vector\n",
    "\n",
    "3) Visualize\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaeb891",
   "metadata": {},
   "source": [
    "## Generate Actual Cases Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "509f8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This file contains incremental day on day cumulative cases across different states\n",
    "cases_tmp = pd.read_csv(Actual_incidence_path+\"US_actual_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80193c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "US_total = pd.DataFrame(cases_tmp.sum(axis=0))\n",
    "\n",
    "cases = pd.concat([cases_tmp,US_total.T])\n",
    "\n",
    "impute = {}\n",
    "\n",
    "impute['Country'] = {'WashingtonIllinoisCaliforniaArizonaMassachusettsWisconsinTexasNebraskaUtahOregonFloridaNew YorkRhode IslandGeorgiaNew HampshireNorth CarolinaNew JerseyColoradoMarylandNevadaTennesseeHawaiiIndianaKentuckyMinnesotaOklahomaPennsylvaniaSouth CarolinaDistrict of ColumbiaKansasMissouriVermontVirginiaConnecticutIowaLouisianaOhioMichiganSouth DakotaArkansasDelawareMississippiNew MexicoNorth DakotaWyomingAlaskaMaineAlabamaIdahoMontanaPuerto RicoVirgin IslandsGuamWest VirginiaNorthern Mariana IslandsAmerican Samoa':\"United States\"}\n",
    "\n",
    "cases = cases.replace(impute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97bf101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22 00:00:00\n",
      "2020-06-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N = 157\n",
    "t = 'Jan 22 2020'\n",
    "format = '%b %d %Y'\n",
    "now = datetime.strptime(t,format)\n",
    "after = now + timedelta(days = N)\n",
    "print(now)\n",
    "print(after)\n",
    "\n",
    "cases_for_use = cases.iloc[:,157:]\n",
    "start = 157\n",
    "\n",
    "days = [i for i in range(start,start+cases_for_use.shape[1])]\n",
    "cases_for_use.columns = days\n",
    "weekly_cases = pd.DataFrame()\n",
    "for i in range(start, start+cases_for_use.shape[1],7):\n",
    "    weekly_cases = pd.concat([weekly_cases,cases_for_use[i]],axis=1)\n",
    "weekly_cases_2 = weekly_cases.copy()\n",
    "\n",
    "\n",
    "weekly_cases_2 = weekly_cases.diff(axis=1)\n",
    "\n",
    "weekly_cases_2[weekly_cases_2<0] = 0\n",
    "\n",
    "\n",
    "\n",
    "weekly_cases1 = weekly_cases_2[list(weekly_cases_2.columns)[1:]]\n",
    "\n",
    "\n",
    "weekly_cases1.index = list(cases['Country'].values)\n",
    "\n",
    "states_list = list(cases['Country'].values)\n",
    "\n",
    "Actual_covid_tally = weekly_cases1.copy()\n",
    "# 2020-6-28 is a Sunday\n",
    "\n",
    "JHU_actual_pd = Actual_covid_tally.copy()\n",
    "\n",
    "data_array = JHU_actual_pd.values\n",
    "\n",
    "week_numbers = JHU_actual_pd.columns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#JHU_actual_pd\n",
    "\n",
    "Actual_covid_tally_dict = Actual_covid_tally.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9102d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Using a sliding window, compute the runnning averages of fixed window sizes\n",
    "\n",
    "\n",
    "state_wise_running_averages = []\n",
    "\n",
    "for state in range(len(states_list)):\n",
    "    vector = data_array[state]\n",
    "    running_average = [0]*len(vector)\n",
    "    \n",
    "    for k in range(len(vector)):\n",
    "        #print(k)\n",
    "        if k==0:\n",
    "#             print(k)\n",
    "#             print(vector[k:k+2])\n",
    "            running_average[k]=sum(vector[k:k+2])/2\n",
    "            \n",
    "        elif k>0 and k < len(vector)-1:\n",
    "            running_average[k] = sum(vector[k-1:k+2])/3\n",
    "        elif k==len(vector)-1:\n",
    "#             print(k)\n",
    "            running_average[k] = sum(vector[k-1:k+1])/2\n",
    "#             print(vector[k-1:k+1])\n",
    "    state_wise_running_averages.append(running_average)\n",
    "    \n",
    "        \n",
    "running_average={}\n",
    "for state in range(len(states_list)):\n",
    "    \n",
    "    running_average[states_list[state]] = list(zip(week_numbers,state_wise_running_averages[state]))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a48150f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orignial_1 = data_array[0]\n",
    "\n",
    "len(orignial_1)\n",
    "\n",
    "len(state_wise_running_averages[0])\n",
    "\n",
    "x = list(range(len(orignial_1)))\n",
    "\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbd0fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ShapeLet_Dictionary_State_level = {}\n",
    "\n",
    "Shapelet_dict_actual_state_week_vector_label = {}\n",
    "\n",
    "for keys in running_average.keys():\n",
    "#     print(keys)\n",
    "    State_name = keys\n",
    "    running_avg = running_average[State_name]\n",
    "\n",
    "\n",
    "\n",
    "    running_avg_vectors = []\n",
    "    for i in range(len(running_avg)):\n",
    "        if i<len(running_avg)-future_weeks:\n",
    "            if i<=history_weeks:\n",
    "                vec = running_avg[i-0:i+future_weeks+history_weeks]\n",
    "            else:\n",
    "                vec = running_avg[i-history_weeks:i+future_weeks]\n",
    "            vec1 = [w[1] for w in vec]\n",
    "            assert len(vec1)==Shapelet_length,\"Size of vector not equal to standard shapelet size\"\n",
    "\n",
    "\n",
    "            week_nbr = vec[0][0]\n",
    "            running_avg_vectors.append((week_nbr,vec1[0],vec1))\n",
    "\n",
    "    dicy_state = Shapelet_dict_actual_state_week_vector_label.get(State_name,{})\n",
    "#     print(dicy_state)\n",
    "#     assert len(vector[2])==Shapelet_length,\"Size of vector not equal to standard shapelet size\"\n",
    "    scenarios_list_pearson_perason = [(vector[0],vector[1],return_best_shapelet_pearson(vector[2]),return_all_shapelet_pearson(vector[2])) for vector in running_avg_vectors]\n",
    "    \n",
    "    for vector in scenarios_list_pearson_perason:\n",
    "        dicy_state[vector[0]] = [(vector[3],vector[2])]\n",
    "    Shapelet_dict_actual_state_week_vector_label[State_name] = dicy_state\n",
    "        \n",
    "\n",
    "    ShapeLet_Dictionary_State_level[keys] = scenarios_list_pearson_perason\n",
    "\n",
    "    ## Actual Covid tally plot validation \n",
    "\n",
    "    week_nbr_plt = [w[0] for w in scenarios_list_pearson_perason]\n",
    "    actual_count_plt = [w[1] for w in scenarios_list_pearson_perason]\n",
    "    labels_plt = [w[2] for w in scenarios_list_pearson_perason]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4ae41eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual_data_PC_data = []\n",
    "for key,value in ShapeLet_Dictionary_State_level.items():\n",
    "    state_anme = key\n",
    "    for vals in value:\n",
    "        week_nbr = vals[0]\n",
    "        week_tally = vals[1]\n",
    "        simialiry_all = vals[3]\n",
    "        Actual_data_PC_data.append([state_anme,week_nbr,week_tally,simialiry_all])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b18cf7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Actual_incidence_simialryDF = pd.DataFrame(Actual_data_PC_data,\\\n",
    "                                           columns=['Location','Week_nbr','Week_Count','Similairty_Actual_All'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a5e19",
   "metadata": {},
   "source": [
    "### Map Model dates with Actual Incidence week numbers for matching cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "42f74dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    val = array[idx]\n",
    "    \n",
    "    \n",
    "    if abs(val-value)>7:\n",
    "        return -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "587b1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_week_nbrs = list(Actual_incidence_simialryDF['Week_nbr'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11e2a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_master_df['mapped_week_nbr'] = model_master_df['forecast_date1'].apply(\\\n",
    "                                                                             lambda x : find_nearest(actual_week_nbrs,x))\n",
    "\n",
    "\n",
    "model_master_df = model_master_df[model_master_df['mapped_week_nbr']!=-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aaab871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_VS_Actual_DF = pd.merge(model_master_df, Actual_incidence_simialryDF,  \\\n",
    "                  how='inner', \\\n",
    "                  left_on=['mapped_week_nbr','location'], \\\n",
    "                  right_on = ['Week_nbr','Location'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5fd00954",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_VS_Actual_DF.drop_duplicates(['model_name','Location','mapped_week_nbr'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5f569",
   "metadata": {},
   "source": [
    "### Mean Aggrement Score Between Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fdf2435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanA_greement_input = Model_VS_Actual_DF[:][['model_name','location','Week_nbr','aggregated_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9d3bda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_tmp = pd.merge(MeanA_greement_input,MeanA_greement_input,\\\n",
    "                          how='inner', \\\n",
    "                  left_on=['Week_nbr','location'], \\\n",
    "                  right_on = ['Week_nbr','location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fdfee9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_models = merge_df_tmp[merge_df_tmp['model_name_x']>merge_df_tmp['model_name_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43409f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    return 1 - spatial.distance.cosine(v1, v2)\n",
    "\n",
    "merge_df_models['Similarity_Score'] = merge_df_models.apply(lambda x: cosine_similarity(x.aggregated_similarity_x, x.aggregated_similarity_y), axis=1)\n",
    "# Model_VS_Actual_DF['Cosine_Score'] = Model_VS_Actual_DF[['aggregated_similarity','Similairty_Actual_All']]\\\n",
    "#                                     .apply(cosine_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cb957c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanSimilarityModels = merge_df_models.groupby(['location','Week_nbr']).agg(Mean_Similarity=(\"Similarity_Score\",\"mean\")).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4fa2230d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/satwant/Documents/Shapelet_method/Shapelet_Methods/Classification_task/Codes\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d748ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanSimilarityModels.to_csv(\"/Users/satwant/Documents/qunatile_mean_agreement.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1bbe1a",
   "metadata": {},
   "source": [
    "## Similarity between Model and Actual Data -- cosine of PC vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ad2e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    return 1 - spatial.distance.cosine(v1, v2)\n",
    "\n",
    "Model_VS_Actual_DF['Cosine_Score'] = Model_VS_Actual_DF.apply(lambda x: cosine_similarity(x.aggregated_similarity, x.Similairty_Actual_All), axis=1)\n",
    "# Model_VS_Actual_DF['Cosine_Score'] = Model_VS_Actual_DF[['aggregated_similarity','Similairty_Actual_All']]\\\n",
    "#                                     .apply(cosine_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a87201db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_VS_Actual_DF_cosine = Model_VS_Actual_DF[['model_name','Location','Week_nbr','Cosine_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3e271a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Week_nbr</th>\n",
       "      <th>Cosine_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JHUAPL-Bucky</td>\n",
       "      <td>California</td>\n",
       "      <td>220</td>\n",
       "      <td>-0.981155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDS-NBDS</td>\n",
       "      <td>California</td>\n",
       "      <td>220</td>\n",
       "      <td>0.999277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CU-nochange</td>\n",
       "      <td>California</td>\n",
       "      <td>220</td>\n",
       "      <td>-0.599175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Covid19Sim-Simulator</td>\n",
       "      <td>California</td>\n",
       "      <td>220</td>\n",
       "      <td>0.997341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COVIDhub-4_week_ensemble</td>\n",
       "      <td>California</td>\n",
       "      <td>220</td>\n",
       "      <td>0.997196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>IowaStateLW-STEM</td>\n",
       "      <td>Florida</td>\n",
       "      <td>178</td>\n",
       "      <td>0.989178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>COVIDhub-ensemble</td>\n",
       "      <td>Florida</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.957073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>UMich-RidgeTfReg</td>\n",
       "      <td>Florida</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.997990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>COVIDhub-baseline</td>\n",
       "      <td>Florida</td>\n",
       "      <td>178</td>\n",
       "      <td>0.905305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>IHME-CurveFit</td>\n",
       "      <td>Florida</td>\n",
       "      <td>178</td>\n",
       "      <td>0.803870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_name    Location  Week_nbr  Cosine_Score\n",
       "0                 JHUAPL-Bucky  California       220     -0.981155\n",
       "1                     DDS-NBDS  California       220      0.999277\n",
       "3                  CU-nochange  California       220     -0.599175\n",
       "4         Covid19Sim-Simulator  California       220      0.997341\n",
       "5     COVIDhub-4_week_ensemble  California       220      0.997196\n",
       "...                        ...         ...       ...           ...\n",
       "4217          IowaStateLW-STEM     Florida       178      0.989178\n",
       "4218         COVIDhub-ensemble     Florida       178     -0.957073\n",
       "4219          UMich-RidgeTfReg     Florida       178     -0.997990\n",
       "4220         COVIDhub-baseline     Florida       178      0.905305\n",
       "4221             IHME-CurveFit     Florida       178      0.803870\n",
       "\n",
       "[3926 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_VS_Actual_DF_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab102a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0632188",
   "metadata": {},
   "source": [
    "## Identify Top performing Models over time - State Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e1f4919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Model_VS_Actual_DF_cosine_1_tmp = Model_VS_Actual_DF_cosine.groupby(['Location','model_name']).agg(Mean_Similarity=(\"Cosine_Score\",\"mean\"),Count_Similarity=(\"Cosine_Score\",\"count\")).reset_index()\n",
    "\n",
    "Model_VS_Actual_DF_cosine_1 = Model_VS_Actual_DF_cosine_1_tmp[Model_VS_Actual_DF_cosine_1['Count_Similarity']>25]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e0a84310",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_VS_Actual_DF_cosine_1\n",
    "\n",
    "\n",
    "Model_VS_Actual_DF_cosine_1[\"rank\"] = Model_VS_Actual_DF_cosine_1.groupby([\"Location\"])[\"Mean_Similarity\"].rank(\"dense\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c5413f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_VS_Actual_DF_cosine_2 = Model_VS_Actual_DF_cosine_1.sort_values(['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "52b28ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>model_name</th>\n",
       "      <th>Mean_Similarity</th>\n",
       "      <th>Count_Similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>California</td>\n",
       "      <td>LNQ-ens1</td>\n",
       "      <td>0.696747</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Florida</td>\n",
       "      <td>LNQ-ens1</td>\n",
       "      <td>0.560701</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>BPagano-RtDriven</td>\n",
       "      <td>0.557760</td>\n",
       "      <td>60</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Florida</td>\n",
       "      <td>Karlen-pypm</td>\n",
       "      <td>0.515491</td>\n",
       "      <td>72</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>COVIDhub-ensemble</td>\n",
       "      <td>0.523444</td>\n",
       "      <td>59</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Florida</td>\n",
       "      <td>CEID-Walk</td>\n",
       "      <td>-0.035735</td>\n",
       "      <td>60</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>California</td>\n",
       "      <td>LANL-GrowthRate</td>\n",
       "      <td>-0.022927</td>\n",
       "      <td>65</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Florida</td>\n",
       "      <td>COVIDhub-baseline</td>\n",
       "      <td>-0.079774</td>\n",
       "      <td>74</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>California</td>\n",
       "      <td>UCLA-SuEIR</td>\n",
       "      <td>-0.107690</td>\n",
       "      <td>50</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>California</td>\n",
       "      <td>UMich-RidgeTfReg</td>\n",
       "      <td>-0.329709</td>\n",
       "      <td>65</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location         model_name  Mean_Similarity  Count_Similarity  rank\n",
       "28  California           LNQ-ens1         0.696747                48   1.0\n",
       "72     Florida           LNQ-ens1         0.560701                48   1.0\n",
       "0   California   BPagano-RtDriven         0.557760                60   2.0\n",
       "70     Florida        Karlen-pypm         0.515491                72   2.0\n",
       "4   California  COVIDhub-ensemble         0.523444                59   3.0\n",
       "..         ...                ...              ...               ...   ...\n",
       "45     Florida          CEID-Walk        -0.035735                60  31.0\n",
       "27  California    LANL-GrowthRate        -0.022927                65  32.0\n",
       "47     Florida  COVIDhub-baseline        -0.079774                74  32.0\n",
       "38  California         UCLA-SuEIR        -0.107690                50  33.0\n",
       "39  California   UMich-RidgeTfReg        -0.329709                65  34.0\n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_VS_Actual_DF_cosine_2.sort_values(['rank','Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa2d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6660a9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c1558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ac0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cd7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
